{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# strainforfard peaks search\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "# peaks search by gauss decomposition\n",
    "import gausspy\n",
    "import gausspy.gp as gp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73458dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ga_file = \"/content/drive/MyDrive/AIRI/RamanSpectra/ga_2_3_5_6.csv\"\n",
    "# fg_file = \"/content/drive/MyDrive/AIRI/RamanSpectra/fg_1-5_7-11.csv\"\n",
    "ga_file = \"dataSrc/ga_2_3_5_6.csv\"\n",
    "fg_file = \"dataSrc/fg_1-5_7-11.csv\"\n",
    "data_ga = pd.read_csv(ga_file, sep=\";\")\n",
    "print(f\"data with GA samples shape: {data_ga.shape}\")\n",
    "data_fg = pd.read_csv(fg_file, sep=\";\")\n",
    "print(f\"data with FG samples shape: {data_fg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fg = data_fg['class'].values\n",
    "X_fg = data_fg.drop(columns=['class'])\n",
    "print(f\"shapes of X and y of FG samples respectively is: {X_fg.shape}, {y_fg.shape}\")\n",
    "\n",
    "y_ga = data_ga['class'].values\n",
    "X_ga = data_ga.drop(columns=['class'])\n",
    "print(f\"shapes of X and y of GA samples respectively is: {X_ga.shape}, {y_ga.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"old fg classes: {set(y_fg)}\")\n",
    "for index, element in enumerate(set(y_fg)):\n",
    "    y_fg[y_fg == element] = index\n",
    "print(f\"new fg classes: {set(y_fg)}\\n\")\n",
    "\n",
    "print(f\"old ga classes: {set(y_ga)}\")\n",
    "for index, element in enumerate(set(y_ga)):\n",
    "    y_ga[y_ga == element] = index + len(set(y_fg))\n",
    "print(f\"new ga classes: {set(y_ga)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = [0, 1, 2, 3, 4]\n",
    "group2 = [5, 6, 7, 8, 9]\n",
    "group3 = [10, 11]\n",
    "group4 = [12, 13]\n",
    "groups = [group1, group2, group3, group4]\n",
    "\n",
    "def add_group(y, groups, add=0):\n",
    "    new_y = np.zeros((y.shape[0], 2))\n",
    "    new_y[:, 1] = y\n",
    "    for group_num, group in enumerate(groups):\n",
    "        for class_num in group:\n",
    "            new_y[y==class_num] = np.array([group_num + add, class_num])\n",
    "    return new_y\n",
    "\n",
    "y_ga = add_group(y_ga, (group3, group4), add=2)\n",
    "y_fg = add_group(y_fg, (group1, group2))\n",
    "print(f\"Now, shapes of y_fg and ga is respectively: {y_ga.shape}, {y_fg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730370e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((y_fg, y_ga), axis=0)\n",
    "X = np.concatenate((X_fg, X_ga), axis=0)\n",
    "X = X.reshape(X.shape[0], 1, -1)\n",
    "print(f\"shapes of X and y is respectively: {X.shape}, {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(tuple(zip(torch.tensor(X_train).float(), torch.tensor(y_train).long())), \n",
    "                                      batch_size=16, \n",
    "                                      shuffle=True)\n",
    "data_loader_test = DataLoader(tuple(zip(torch.tensor(X_test).float(), torch.tensor(y_test).long())), \n",
    "                                     batch_size=16, \n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38554db7",
   "metadata": {},
   "source": [
    "## Неудачное разложение на гауссианы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILENAME, 'w'):\n",
    "    pass\n",
    "\n",
    "with open(FILENAME_DECOMP, 'w'):\n",
    "    pass\n",
    "\n",
    "# Data properties\n",
    "RMS = 1\n",
    "NCHANNELS = 994\n",
    "FILENAME = 'simple_gaussian.pickle'\n",
    "\n",
    "# Component properties\n",
    "\n",
    "# Initialize\n",
    "data = {}\n",
    "# chan = np.arange(NCHANNELS)\n",
    "chan = data_fg.columns[1:].values.astype(float)\n",
    "# [float(digit) for digit in data_fg.columns[1:].values]\n",
    "errors = np.ones(NCHANNELS) * RMS\n",
    "\n",
    "# spectrum = np.random.randn(NCHANNELS) * RMS\n",
    "# spectrum += gaussian(AMP, FWHM, MEAN)(chan)\n",
    "spectrum = savgol_filter(X[-1].reshape(-1), 15, 2)\n",
    "# savgol_filter(X[-1].reshape(-1), 75, 2)\n",
    "print(spectrum.shape, chan.shape)\n",
    "\n",
    "# Enter results into AGD dataset\n",
    "data['data_list'] = [spectrum]\n",
    "data['x_values'] = [chan]\n",
    "data['errors'] = [errors]\n",
    "\n",
    "\n",
    "pickle.dump(data, open(FILENAME, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing parameter\n",
    "alpha1 = 0.05\n",
    "# the signal-to-noise ratio threshold below which amplitude GaussPy will not fit a component.\n",
    "snr_thresh = 1\n",
    "FILENAME = 'simple_gaussian.pickle'\n",
    "FILENAME_DECOMP = 'simple_gaussian_decomposed.pickle'\n",
    "\n",
    "# Load GaussPy\n",
    "g = gp.GaussianDecomposer()\n",
    "\n",
    "# Setting AGD parameters\n",
    "g.set('phase', 'one')\n",
    "g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "g.set('alpha1', alpha1)\n",
    "\n",
    "# Run GaussPy\n",
    "data_decomp = g.batch_decomposition(FILENAME)\n",
    "\n",
    "# Save decomposition information\n",
    "pickle.dump(data_decomp, open(FILENAME_DECOMP, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(amp, fwhm, mean):\n",
    "    return lambda x: amp * np.exp(-4. * np.log(2) * (x-mean)**2 / fwhm**2)\n",
    "\n",
    "def unravel(List):\n",
    "    return np.array([i for array in List for i in array])\n",
    "\n",
    "FILENAME = 'simple_gaussian.pickle'\n",
    "FILENAME_DECOMP = 'simple_gaussian_decomposed.pickle'\n",
    "\n",
    "data = pickle.load(open(FILENAME, 'rb'))\n",
    "spectrum = unravel(data['data_list'])\n",
    "chan = unravel(data['x_values'])\n",
    "errors = unravel(data['errors'])\n",
    "\n",
    "data_decomp = pickle.load(open(FILENAME_DECOMP, 'rb'))\n",
    "means_fit = unravel(data_decomp['means_fit'])\n",
    "amps_fit = unravel(data_decomp['amplitudes_fit'])\n",
    "fwhms_fit = unravel(data_decomp['fwhms_fit'])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "model = np.zeros(len(chan))\n",
    "\n",
    "for j in range(len(means_fit)):\n",
    "    component = gaussian(amps_fit[j], fwhms_fit[j], means_fit[j])(chan)\n",
    "    model += component\n",
    "    ax.plot(chan, component, color='red', lw=1.5)\n",
    "\n",
    "ax.plot(chan, spectrum, label='Data', color='black', linewidth=1.5)\n",
    "ax.plot(chan, model, label = f'$log \\\\alpha={alpha1}$', color='purple', linewidth=2.)\n",
    "# ax.plot(chan, errors, label = 'Errors', color='green', linestyle='dashed', linewidth=2.)\n",
    "\n",
    "ax.set_xlabel('Channels', fontsize=15)\n",
    "ax.set_ylabel('Amplitude', fontsize=15)\n",
    "\n",
    "ax.set_xlim(chan.min()-30,chan.max()+30)\n",
    "ax.set_ylim(np.min(spectrum),np.max(spectrum))\n",
    "ax.legend(loc=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "max_array = []\n",
    "max_alpha = 0\n",
    "max_snr = 0\n",
    "for j in np.linspace(0.2, 3, 15):\n",
    "    for i in np.linspace(0.1, 1, 10):\n",
    "        alpha1 = i\n",
    "        # the signal-to-noise ratio threshold below which amplitude GaussPy will not fit a component.\n",
    "        snr_thresh = j\n",
    "        FILENAME = 'simple_gaussian.pickle'\n",
    "        FILENAME_DECOMP = 'simple_gaussian_decomposed.pickle'\n",
    "\n",
    "        # Load GaussPy\n",
    "        g = gp.GaussianDecomposer()\n",
    "\n",
    "        # Setting AGD parameters\n",
    "        g.set('phase', 'one')\n",
    "        g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "        g.set('alpha1', alpha1)\n",
    "\n",
    "        # Run GaussPy\n",
    "        data_decomp = g.batch_decomposition(FILENAME)\n",
    "\n",
    "        # Save decomposition information\n",
    "        pickle.dump(data_decomp, open(FILENAME_DECOMP, 'wb'))\n",
    "\n",
    "        data = pickle.load(open(FILENAME, 'rb'))\n",
    "        spectrum = unravel(data['data_list'])\n",
    "        chan = unravel(data['x_values'])\n",
    "        errors = unravel(data['errors'])\n",
    "\n",
    "        data_decomp = pickle.load(open(FILENAME_DECOMP, 'rb'))\n",
    "        means_fit = unravel(data_decomp['means_fit'])\n",
    "        amps_fit = unravel(data_decomp['amplitudes_fit'])\n",
    "        fwhms_fit = unravel(data_decomp['fwhms_fit'])\n",
    "\n",
    "    #     fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "    #     ax = fig.add_subplot(111)\n",
    "\n",
    "    #     model = np.zeros(len(chan))\n",
    "\n",
    "    #     for j in range(len(means_fit)):\n",
    "    #         component = gaussian(amps_fit[j], fwhms_fit[j], means_fit[j])(chan)\n",
    "    #         model += component\n",
    "    #         ax.plot(chan, component, color='red', lw=1.5)\n",
    "\n",
    "    #     ax.plot(chan, spectrum, label='Data', color='black', linewidth=1.5)\n",
    "    #     ax.plot(chan, model, label = f'$log \\\\alpha={alpha1}$', color='purple', linewidth=2.)\n",
    "        # ax.plot(chan, errors, label = 'Errors', color='green', linestyle='dashed', linewidth=2.)\n",
    "\n",
    "    #     ax.set_xlabel('Channels', fontsize=15)\n",
    "    #     ax.set_ylabel('Amplitude', fontsize=15)\n",
    "    #     ax.set_xlim(chan.min()-30,chan.max()+30)\n",
    "    #     ax.set_ylim(np.min(spectrum),np.max(spectrum))\n",
    "    #     ax.legend(loc=2)\n",
    "        if len(means_fit) > max_len:\n",
    "            max_len = len(means_fit)\n",
    "            max_array = means_fit\n",
    "            max_alpha = alpha1\n",
    "            max_snr = snr_thresh\n",
    "        print(f\"alpha = {alpha1}, snr_thresh = {snr_thresh}, means_fit:\\n{means_fit}\")\n",
    "    #     plt.show()\n",
    "print(max_len, max_alpha, max_snr, max_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db45a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_len, max_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
